#!/usr/bin/env python3
"""
Alpaca Live Trading ä¸€ä½“åŒ–æµç¨‹:
1) è¯»å– position.jsonl / balance.jsonl
2) åˆ†æè‚¡ç¥¨æ± ï¼ˆé»˜è®¤ 101 åªï¼‰:
   - AlphaVantage åŸºæœ¬é¢
   - AlphaVantage æ–°é—»ä¸æƒ…ç»ª
   - Polymarket å¸‚åœºèµ”ç‡
   - tvscreener ä»·æ ¼ä¸æŠ€æœ¯é¢
3) å¯é€‰æ‰§è¡Œäº¤æ˜“è®¡åˆ’
4) äº¤æ˜“åæ›´æ–° position.jsonl / balance.jsonlï¼ˆç”± execute_alpaca_trade.py å®Œæˆï¼‰
"""

from __future__ import annotations

import argparse
import json
import re
import subprocess
import sys
from datetime import datetime
from pathlib import Path
from typing import Any, Dict, List, Optional, Tuple

# ç¡®ä¿å¯ä»¥å¯¼å…¥åŒç›®å½•è„šæœ¬
SCRIPT_DIR = Path(__file__).resolve().parent
sys.path.insert(0, str(SCRIPT_DIR))

from query_fundamentals import fetch_fundamentals_for_symbol
from query_market_news import fetch_news_per_ticker
from query_polymarket_sentiment import get_financial_sentiment
from query_stock_prices import DEFAULT_SYMBOLS, _load_market_snapshot, get_quote


def _read_jsonl(path: Path) -> List[Dict[str, Any]]:
    if not path.exists():
        return []
    rows: List[Dict[str, Any]] = []
    with open(path, "r", encoding="utf-8") as f:
        for line in f:
            line = line.strip()
            if not line:
                continue
            try:
                rows.append(json.loads(line))
            except Exception:
                continue
    return rows


def _tail_rows(rows: List[Dict[str, Any]], n: int = 5) -> List[Dict[str, Any]]:
    return rows[-n:] if len(rows) > n else rows


def _execute_trade_plan(trade_plan: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
    exec_script = SCRIPT_DIR / "execute_alpaca_trade.py"
    results: List[Dict[str, Any]] = []
    for item in trade_plan:
        action = str(item.get("action", "")).lower().strip()
        symbol = str(item.get("symbol", "")).upper().strip()
        qty = int(item.get("qty", 0))
        if action not in {"buy", "sell"} or not symbol or qty <= 0:
            results.append(
                {
                    "status": "skipped",
                    "input": item,
                    "reason": "invalid action/symbol/qty",
                }
            )
            continue

        cmd = [
            sys.executable,
            str(exec_script),
            "--action",
            action,
            "--symbol",
            symbol,
            "--qty",
            str(qty),
            "--json",
        ]
        completed = subprocess.run(
            cmd,
            capture_output=True,
            text=True,
            check=False,
        )
        if completed.returncode == 0:
            try:
                payload = json.loads(completed.stdout)
                results.append({"status": "ok", "trade": payload})
            except Exception:
                results.append(
                    {
                        "status": "ok_non_json",
                        "stdout": completed.stdout,
                        "stderr": completed.stderr,
                    }
                )
        else:
            results.append(
                {
                    "status": "failed",
                    "input": item,
                    "returncode": completed.returncode,
                    "stdout": completed.stdout,
                    "stderr": completed.stderr,
                }
            )
    return results


def _to_float(v: Any) -> Optional[float]:
    try:
        if v is None:
            return None
        return float(v)
    except (TypeError, ValueError):
        return None


def _parse_av_time(ts: str) -> Optional[datetime]:
    if not ts:
        return None
    try:
        # AlphaVantage time format: YYYYMMDDTHHMMSS
        return datetime.strptime(ts[:15], "%Y%m%dT%H%M%S")
    except Exception:
        return None


def _article_signal(article: Dict[str, Any]) -> float:
    ticker_score = _to_float(article.get("target_ticker_sentiment_score"))
    overall_score = _to_float(article.get("overall_sentiment_score"))
    if ticker_score is not None and overall_score is not None:
        return 0.7 * ticker_score + 0.3 * overall_score
    if ticker_score is not None:
        return ticker_score
    if overall_score is not None:
        return overall_score
    return 0.0


def _compute_news_rank(item: Dict[str, Any]) -> Dict[str, Any]:
    articles = item.get("articles", []) or []
    scores: List[float] = []
    if not articles:
        return {
            "ticker": item.get("ticker"),
            "news_count": 0,
            "avg_ticker_sentiment_score": item.get("avg_ticker_sentiment_score"),
            "avg_overall_sentiment_score": item.get("avg_overall_sentiment_score"),
            "momentum_score": -1.0,
        }

    latest_ts = max((_parse_av_time(a.get("time_published", "")) for a in articles), default=None)
    for a in articles:
        base = _article_signal(a)
        ts = _parse_av_time(a.get("time_published", ""))
        if latest_ts is not None and ts is not None:
            delta_hours = max((latest_ts - ts).total_seconds() / 3600.0, 0.0)
            recency_weight = 1.0 / (1.0 + delta_hours / 24.0)  # åŠè¡°è¿‘ä¼¼ï¼šæŒ‰å¤©è¡°å‡
        else:
            recency_weight = 0.7
        scores.append(base * recency_weight)

    # å°‘æ ·æœ¬æƒ©ç½šï¼Œé¿å… 1-2 æ¡æ–°é—»å™ªå£°è¿‡å¤§
    count = len(articles)
    count_penalty = min(count / 5.0, 1.0)
    momentum = (sum(scores) / max(count, 1)) * count_penalty
    return {
        "ticker": item.get("ticker"),
        "news_count": count,
        "avg_ticker_sentiment_score": item.get("avg_ticker_sentiment_score"),
        "avg_overall_sentiment_score": item.get("avg_overall_sentiment_score"),
        "momentum_score": round(momentum, 6),
    }


def _select_top_by_news(news_items: List[Dict[str, Any]], top_k: int) -> Tuple[List[str], List[Dict[str, Any]]]:
    scored = [_compute_news_rank(item) for item in news_items]
    ranked = sorted(
        scored,
        key=lambda x: (
            _to_float(x.get("momentum_score")) if _to_float(x.get("momentum_score")) is not None else -999,
            _to_float(x.get("avg_ticker_sentiment_score")) if _to_float(x.get("avg_ticker_sentiment_score")) is not None else -999,
            x.get("news_count", 0),
        ),
        reverse=True,
    )
    selected = [x.get("ticker") for x in ranked[:top_k] if x.get("ticker")]
    return selected, ranked


def _extract_polymarket_market_signal(polymarket_text: str) -> Optional[float]:
    if not polymarket_text:
        return None
    signals: List[float] = []
    # ç®€å•æŠ½å–ï¼šS&P500/NASDAQ å½“æ—¥ä¸Šæ¶¨æ¦‚ç‡
    patterns = [
        r"S&P 500.*?\|\s*Yes:\s*([0-9]+(?:\.[0-9]+)?)%",
        r"NASDAQ.*?\|\s*Yes:\s*([0-9]+(?:\.[0-9]+)?)%",
    ]
    for pat in patterns:
        m = re.search(pat, polymarket_text, flags=re.IGNORECASE | re.DOTALL)
        if m:
            yes_prob = float(m.group(1)) / 100.0
            # æ¦‚ç‡æ˜ å°„åˆ° [-1, 1]
            signals.append((yes_prob - 0.5) * 2.0)
    if not signals:
        return None
    return sum(signals) / len(signals)


def _extract_benchmark_signal(news_items: List[Dict[str, Any]], benchmark_tickers: List[str]) -> Optional[float]:
    values: List[float] = []
    targets = {t.upper() for t in benchmark_tickers}
    for item in news_items:
        if str(item.get("ticker", "")).upper() not in targets:
            continue
        v = _to_float(item.get("avg_ticker_sentiment_score"))
        if v is None:
            v = _to_float(item.get("avg_overall_sentiment_score"))
        if v is not None:
            values.append(v)
    if not values:
        return None
    return sum(values) / len(values)


def _dedupe_keep_order(items: List[str]) -> List[str]:
    seen = set()
    out: List[str] = []
    for x in items:
        if x not in seen:
            out.append(x)
            seen.add(x)
    return out


def main() -> None:
    parser = argparse.ArgumentParser(description="è¿è¡Œ Alpaca åˆ†æ+äº¤æ˜“ä¸€ä½“åŒ–æµç¨‹")
    parser.add_argument(
        "--tickers",
        type=str,
        default="",
        help="è‚¡ç¥¨åˆ—è¡¨ï¼Œé€—å·åˆ†éš”ï¼›ä¸ºç©ºæ—¶é»˜è®¤ NASDAQ100+QQQ å…±101åª",
    )
    parser.add_argument("--days", type=int, default=365, help="åŸºæœ¬é¢å›çœ‹å¤©æ•°ï¼Œé»˜è®¤365")
    parser.add_argument("--news-limit", type=int, default=5, help="æ¯åªè‚¡ç¥¨æ–°é—»æ¡æ•°ï¼Œé»˜è®¤5")
    parser.add_argument("--prefilter-top-k", type=int, default=10, help="ç¬¬ä¸€é˜¶æ®µæ–°é—»ç­›é€‰åä¿ç•™æ•°é‡ï¼Œé»˜è®¤10")
    parser.add_argument(
        "--benchmark-tickers",
        type=str,
        default="QQQ,SPY",
        help="ç¬¬äºŒé˜¶æ®µå¸‚åœºé—¨æ§åŸºå‡†ä»£ç ï¼Œé»˜è®¤ QQQ,SPY",
    )
    parser.add_argument(
        "--market-gate-threshold",
        type=float,
        default=-0.05,
        help="å¸‚åœºé—¨æ§é˜ˆå€¼ï¼Œä½äºè¯¥å€¼ä¸æ‰§è¡Œäº¤æ˜“ï¼Œé»˜è®¤ -0.05",
    )
    parser.add_argument(
        "--av-calls-per-minute",
        type=float,
        default=75.0,
        help="AlphaVantage é™é€Ÿï¼Œé»˜è®¤ 75 æ¬¡/åˆ†é’Ÿ",
    )
    parser.add_argument(
        "--trade-plan-file",
        type=str,
        default="",
        help="äº¤æ˜“è®¡åˆ’ JSON æ–‡ä»¶è·¯å¾„ï¼ˆåˆ—è¡¨æ ¼å¼: [{action,symbol,qty}, ...]ï¼‰",
    )
    parser.add_argument(
        "--execute-trades",
        action="store_true",
        help="æ˜¯å¦å®é™…æ‰§è¡Œäº¤æ˜“ï¼ˆæœªå¼€å¯ä»…åˆ†æä¸äº¤æ˜“ï¼‰",
    )
    parser.add_argument(
        "--output-file",
        type=str,
        default="skills/alpaca-live-trading/data/analysis_pipeline_latest.json",
        help="è¾“å‡ºåˆ†æç»“æœ JSON æ–‡ä»¶",
    )
    args = parser.parse_args()

    tickers = (
        [s.strip().upper() for s in args.tickers.split(",") if s.strip()]
        if args.tickers
        else DEFAULT_SYMBOLS.copy()
    )
    if not tickers:
        print("âŒ è‚¡ç¥¨åˆ—è¡¨ä¸ºç©º")
        raise SystemExit(1)

    interval = 60.0 / max(args.av_calls_per_minute, 1.0)
    print(f"ğŸš€ å¯åŠ¨æµç¨‹ï¼Œè‚¡ç¥¨æ•°: {len(tickers)}ï¼ŒAlphaVantage èŠ‚æµ: {interval:.3f}s/æ¬¡")

    # 0) è¯»å–å·²æœ‰çŠ¶æ€
    data_dir = SCRIPT_DIR.parent / "data"
    position_path = data_dir / "position" / "position.jsonl"
    balance_path = data_dir / "balance" / "balance.jsonl"
    old_positions = _read_jsonl(position_path)
    old_balances = _read_jsonl(balance_path)

    # ç¬¬ä¸€é˜¶æ®µï¼šå¯¹å…¨æ± åšæ–°é—»/æƒ…ç»ªç­›é€‰
    print("ğŸ“° ç¬¬ä¸€é˜¶æ®µï¼š101æ± æ–°é—»ä¸æƒ…ç»ªç­›é€‰...")
    stage1_news = fetch_news_per_ticker(
        tickers=tickers,
        per_ticker_limit=max(1, args.news_limit),
        sort="LATEST",
        request_interval=interval,
    )
    top_k = max(1, args.prefilter_top_k)
    top10, ranking = _select_top_by_news(stage1_news, top_k=top_k)
    print(f"âœ… ç¬¬ä¸€é˜¶æ®µå®Œæˆï¼Œå…¥é€‰ Top{top_k}: {top10}")

    benchmark_tickers = [x.strip().upper() for x in args.benchmark_tickers.split(",") if x.strip()]
    deep_universe = _dedupe_keep_order(top10 + benchmark_tickers)
    print(f"ğŸ” ç¬¬äºŒé˜¶æ®µæ·±åº¦åˆ†ææ ‡çš„æ•°: {len(deep_universe)}")

    # ç¬¬äºŒé˜¶æ®µï¼šæ·±åº¦åˆ†æï¼ˆTop10 + QQQ/SPYï¼‰
    print("ğŸ“° ç¬¬äºŒé˜¶æ®µï¼šTopæ ‡çš„ + åŸºå‡†ETF æ–°é—»æƒ…ç»ª...")
    deep_news = fetch_news_per_ticker(
        tickers=deep_universe,
        per_ticker_limit=max(1, args.news_limit),
        sort="LATEST",
        request_interval=interval,
    )

    print("ğŸ“š ç¬¬äºŒé˜¶æ®µï¼šåŸºæœ¬é¢...")
    fundamentals: List[Dict[str, Any]] = []
    for idx, ticker in enumerate(deep_universe, 1):
        print(f"[{idx}/{len(deep_universe)}] åŸºæœ¬é¢: {ticker}")
        try:
            fundamentals.append(
                fetch_fundamentals_for_symbol(
                    ticker,
                    days=args.days,
                    endpoint_request_interval=interval,
                )
            )
        except Exception as e:
            fundamentals.append({"symbol": ticker, "error": str(e)})

    # Polymarket å¸‚åœºèµ”ç‡
    print("ğŸ“Š è·å– Polymarket èµ”ç‡...")
    try:
        polymarket = get_financial_sentiment()
    except Exception as e:
        polymarket = f"ERROR: {e}"

    # tvscreener ä»·æ ¼ + æŠ€æœ¯é¢
    print("ğŸ“ˆ ç¬¬äºŒé˜¶æ®µï¼štvscreener ä»·æ ¼ä¸æŠ€æœ¯é¢...")
    snapshot = _load_market_snapshot()
    quotes: List[Dict[str, Any]] = []
    for ticker in deep_universe:
        quotes.append(get_quote(ticker, snapshot))

    benchmark_news_signal = _extract_benchmark_signal(deep_news, benchmark_tickers)
    polymarket_signal = _extract_polymarket_market_signal(polymarket if isinstance(polymarket, str) else "")
    signal_values = [v for v in [benchmark_news_signal, polymarket_signal] if v is not None]
    market_gate_score = sum(signal_values) / len(signal_values) if signal_values else None
    should_trade_by_market = market_gate_score is not None and market_gate_score >= args.market_gate_threshold
    if market_gate_score is None:
        # æ²¡æœ‰å¸‚åœºä¿¡å·æ—¶ï¼Œä¿å®ˆæ”¾è¡Œï¼Œé¿å…ç­–ç•¥å®Œå…¨åœæ‘†
        should_trade_by_market = True

    # å¯é€‰äº¤æ˜“æ‰§è¡Œï¼ˆå—å¸‚åœºé—¨æ§ï¼‰
    trade_results: List[Dict[str, Any]] = []
    trade_plan: List[Dict[str, Any]] = []
    if args.trade_plan_file:
        plan_path = Path(args.trade_plan_file)
        if plan_path.exists():
            try:
                trade_plan = json.loads(plan_path.read_text(encoding="utf-8"))
                if not isinstance(trade_plan, list):
                    raise ValueError("äº¤æ˜“è®¡åˆ’æ–‡ä»¶å¿…é¡»æ˜¯ JSON åˆ—è¡¨")
            except Exception as e:
                print(f"âš ï¸ è¯»å–äº¤æ˜“è®¡åˆ’å¤±è´¥: {e}")
                trade_plan = []
        else:
            print(f"âš ï¸ äº¤æ˜“è®¡åˆ’æ–‡ä»¶ä¸å­˜åœ¨: {plan_path}")

    if args.execute_trades and trade_plan and should_trade_by_market:
        print(f"ğŸ§¾ æ‰§è¡Œäº¤æ˜“è®¡åˆ’ï¼Œå…± {len(trade_plan)} æ¡...")
        trade_results = _execute_trade_plan(trade_plan)
    elif args.execute_trades and trade_plan and not should_trade_by_market:
        print("ğŸ›‘ å¸‚åœºé—¨æ§æœªé€šè¿‡ï¼Œè·³è¿‡æ‰§è¡Œäº¤æ˜“ã€‚")
        trade_results = [{"status": "blocked_by_market_gate", "market_gate_score": market_gate_score}]
    elif args.execute_trades:
        print("âš ï¸ å·²æŒ‡å®šæ‰§è¡Œäº¤æ˜“ï¼Œä½†äº¤æ˜“è®¡åˆ’ä¸ºç©ºï¼Œè·³è¿‡æ‰§è¡Œã€‚")

    # 6) è¯»å–äº¤æ˜“åçŠ¶æ€
    new_positions = _read_jsonl(position_path)
    new_balances = _read_jsonl(balance_path)

    output = {
        "generated_at": datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
        "tickers_count": len(tickers),
        "tickers": tickers,
        "pipeline": {
            "stage1_prefilter": {
                "input_universe_size": len(tickers),
                "news_limit_per_ticker": args.news_limit,
                "top_k": top_k,
                "ranking": ranking,
                "selected_top_tickers": top10,
            },
            "stage2_deep_analysis": {
                "benchmark_tickers": benchmark_tickers,
                "deep_universe": deep_universe,
                "deep_universe_size": len(deep_universe),
            },
            "market_gate": {
                "benchmark_news_signal": benchmark_news_signal,
                "polymarket_signal": polymarket_signal,
                "market_gate_score": market_gate_score,
                "threshold": args.market_gate_threshold,
                "should_trade": should_trade_by_market,
            },
        },
        "alpha_vantage": {
            "calls_per_minute": args.av_calls_per_minute,
            "request_interval_seconds": interval,
            "fundamentals": fundamentals,
            "news_sentiment_stage1": stage1_news,
            "news_sentiment_stage2": deep_news,
        },
        "polymarket_sentiment": polymarket,
        "tvscreener": {
            "quotes": quotes,
        },
        "state_before": {
            "position_path": str(position_path),
            "balance_path": str(balance_path),
            "position_tail": _tail_rows(old_positions, 5),
            "balance_tail": _tail_rows(old_balances, 5),
        },
        "trade_execution": {
            "enabled": bool(args.execute_trades),
            "trade_plan": trade_plan,
            "results": trade_results,
        },
        "state_after": {
            "position_tail": _tail_rows(new_positions, 5),
            "balance_tail": _tail_rows(new_balances, 5),
        },
    }

    out_path = Path(args.output_file)
    out_path.parent.mkdir(parents=True, exist_ok=True)
    out_path.write_text(json.dumps(output, ensure_ascii=False, indent=2), encoding="utf-8")
    print(f"âœ… æµç¨‹å®Œæˆï¼Œç»“æœå·²å†™å…¥: {out_path}")


if __name__ == "__main__":
    main()
